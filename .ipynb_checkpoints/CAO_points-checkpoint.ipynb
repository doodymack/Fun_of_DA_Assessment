{
 "cells": [
  {
   "cell_type": "raw",
   "id": "be73e9b8-6497-4af5-973a-4b7f41cda73a",
   "metadata": {},
   "source": [
    " ## CAO Points Notebook\n",
    " \n",
    " - clear and concise overview of how to load CAO points info from the CAO website into a PANDAS dataframe\n",
    " - Detailed comparison of CAO points in 2019,2020,2021 using the functionality in pandas\n",
    " - Appropriate plots and other visuaizations to enhance your notebook for viewers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68dfe20-0244-46d7-b5e4-3b94baed31a7",
   "metadata": {},
   "source": [
    "http://www2.cao.ie/points/l8.php\n",
    "\n",
    "***\n",
    "'PHP' indicates that the webpage has been programmed using PHP, a server side scripting language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa310ef9-c0c1-41e2-80c2-93a0b0ce333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convenient http requests\n",
    "import requests as rq\n",
    "\n",
    "# regular expressions\n",
    "import re\n",
    "\n",
    "#dates and times\n",
    "import datetime as dt\n",
    "\n",
    "# for dataframes import pandas\n",
    "# v useful to get data from spreadsheets\n",
    "import pandas as pd\n",
    "\n",
    "#for downloading files to python\n",
    "import urllib.request as urlrq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0758b41-4462-421d-82d1-e3d7a77d428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399626a3-4075-4c6d-8c12-8ca93557b3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 12, 3, 20, 29, 45, 690848)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datetime function has a data structure called datetime\n",
    "#field for time, day ,month etc\n",
    "#dt.datetime.now()\n",
    "now = dt.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430df60b-1073-431b-b72d-2bf14791e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20211203_202945'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format now as a string\n",
    "#if have datetimestamp as separate and unique at the start of the notebook\n",
    "# then potentially can overwrite but on positive side all files \n",
    "# created in logbook run will have the same datetimestamp so neater and can track\n",
    "#2020 datafile saved as'now' file is equivalent to corresponding 2021 saved as same'now' etc\n",
    "now.strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc02c6bd-28e1-4ad1-b9d9-a7e9a063854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 20:29:45.690848\n"
     ]
    }
   ],
   "source": [
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f6192-45a8-4b85-a378-960f019feaf5",
   "metadata": {},
   "source": [
    "# 2021 points\n",
    "\n",
    "http://www2.cao.ie/points/l8.php\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fe408f-2e6c-4bed-818a-2c6bd017383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the CAO points URL\n",
    "# resp= response from the URL\n",
    "# rq= request library\n",
    "# get= get the url (NB: gets the HTTP version!)\n",
    "resp = rq.get ('http://www2.cao.ie/points/l8.php')\n",
    "#have a quick peek\n",
    "resp\n",
    "# resp [200] means html response is in order.  [404] if returns means it is not found .  These are http codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249bc87-f081-4e75-973b-3e4841a2673b",
   "metadata": {},
   "source": [
    "### use the current time as a filename - need to remove colons, decimal points etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c235c6e6-c5d5-4c7b-9153-4383e3404956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good programmers use only alphanumeric characters,dash and dot in file names\n",
    "#create a filepath for the original data\n",
    "#use year at start to ensure alphabetic sorted when filed\n",
    "# below creates the EMPTY html file and saves it in a new 'data' folder in active location  ie. \\repo\\Fun_of..\n",
    "path2021html = 'data/cao2021_' + now.strftime('%Y%m%d_%H%M%S')  + '.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cb10c-9ba2-4526-994d-150440842351",
   "metadata": {},
   "source": [
    "### the server uses the wrong encoding fix it before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602ab426-3d20-4773-94dd-1fc72f2b6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESP = RESPONSE\n",
    "#'resp.text' takes the response and converts it to text- but still has original errors\n",
    "#thus not best way to save THIS original file\n",
    "#but resp.text is a typical way to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4567c7-682e-432e-97ce-c40f3de452d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_encoding = resp.encoding\n",
    "resp.encoding = 'cp1252'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1835331-dbf7-471a-a0ca-173f7c4f4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the original html file:\n",
    "# using the updated coding cp1252 as a TEXT file\n",
    "#this file is not used in the regular expression script but saved as a record \n",
    "\n",
    "with open(path2021html, 'w') as f:\n",
    "    f.write(resp.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101e4289-992b-4698-a768-9906d1f557cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python looks for html codes such as \\n \\t\n",
    "#\\n is a new line (common Unix command)\n",
    "#resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cb7f4-e306-459c-be40-f29e2a2e9aad",
   "metadata": {},
   "source": [
    "https://stackabuse.com/pythons-itertools-count-cycle-and-chain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64b862-8c9f-42fc-8e2c-550fb004727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to loop through (iterate through) the lines in request. \n",
    "for line in resp.iter_lines(): \n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814bb1a8-947b-4530-a360-1accabfe4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the regular expression for matching lines\n",
    "# re= regular expression. Each character is a string but together form an instruction.\n",
    "# r' = 'raw' used in python. It means don't evaluate backslashes in encountered string literals  i.e. \\n \\t i.e \n",
    "re_course = re.compile(r'([A-Z]{2}[0-9]{3})  (.*)([0-9]{3})(\\*?) *')\n",
    "\n",
    "#shortened RE to simplify i.e. does the line have two alphabetic characters followed by three numbers followed by anything else\n",
    "#re_course = re.compile(r'([A-Z]{2}[0-9]{3})(.*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0badf134-5209-44f1-8793-98bf3f1b20d4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**error on the server= way to fix**\n",
    "\n",
    "match only the lines we want -the ones representing courses \n",
    " technically the server says we should decode as:\n",
    " \n",
    "content-type: text/html; charset: iso-8859-1\n",
    "\n",
    "  but\n",
    "    -one line uses /x96 which isn't defined in iso-8859-1\n",
    "    -therefore we used the similiar decoding standard (codec) cp-1252 which is very similar but includes \\x96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79da0d0-5bab-48f9-9086-27e607abb1be",
   "metadata": {},
   "source": [
    "### loop through the lines of the response\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49b2130b-f8ca-42ad-8e82-6a9f3e6bddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the filepath for the csv file- which is the output of the below script\n",
    "path2021csv = 'data/cao2021_csv' + now.strftime('%Y%m%d_%H%M%S')  + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a6369c2-cb38-48b6-859b-b9706dd36231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of lines is 922.\n"
     ]
    }
   ],
   "source": [
    "#for the below if used in assessment should be cleaned up. Check regular expressions are working properly\n",
    "# if want to save output of this then need a filepath and file format like the original data above\n",
    "\n",
    "no_lines = 0\n",
    "#open the csv file for writing\n",
    "with open(path2021csv, 'w') as f:\n",
    "    # write a header row\n",
    "    f.write(','.join(['code', 'title', 'pointsR1', 'pointsR2']) + '\\n')\n",
    "   # f.write(resp.text)   \n",
    "    #loop through the lines of the response content\n",
    "    for line in resp.iter_lines():\n",
    "        #decode the line using the encoding not flagged by the response from CAO\n",
    "        decoded_line = line.decode('cp1252')\n",
    "        #match only the lines representing the requirements of the regular expression (i.e. line containing course)\n",
    "        if re_course.fullmatch(decoded_line):\n",
    "            #add one to the line counter\n",
    "            no_lines = no_lines + 1\n",
    "            #print(line)# to check the output- can be commented out as required\n",
    "\n",
    "        # version 1 using regular expression\n",
    "        # csv_version = re_course.sub(r'\\1,\\2,\\3,\\4', dline)\n",
    "        #version 1 using re commented out\n",
    "        #print(csv_version) no need to print so commented out\n",
    "        #alternate way than regular expression is to use python in built split function\n",
    "        # 'split' splits the line\n",
    "        #(+ ) instructs to do this where two or more spaces- NB the spaces represented before the '+' below are v important\n",
    "            linesplit = re.split('  +', decoded_line)\n",
    "\n",
    "            f.write(','.join(linesplit) + '\\n') \n",
    "print(f\"total number of lines is {no_lines}.\")    \n",
    "# long outputs are a pain in github as will render without the abiliity to scroll. \n",
    "# Therefore don't print it all out.   \n",
    "# Can use scikit learn. Suggestion below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3420c-f87e-4043-9b1b-939e341d7b43",
   "metadata": {},
   "source": [
    "#### regular expression syntax\n",
    "https://www.w3schools.com/python/python_regex.asp\n",
    "\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "#### how to use split function\n",
    "https://pynative.com/python-regex-split/#h-how-to-use-re-split-function\n",
    "\n",
    "syntax: re.split(pattern, string, maxsplit=0, flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05fa60ab-6203-422a-8e2f-1c9b5fbc8c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2e+01\n",
      "-2e+01\n",
      "-1e+01\n",
      "-1e+01\n",
      "-8e+00\n",
      "-5e+00\n",
      "-2e+00\n",
      "1e+00\n",
      "4e+00\n",
      "7e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# o upto 10000 (not including)\n",
    "x = np.linspace(-20.0, 10.0,10000)\n",
    "#i = 0\n",
    "#for i in x\n",
    "# evertyime i is a multiple of 1000\n",
    "for i in range (len(x)):\n",
    "    if (i % 1000) == 0:\n",
    "        print (f\"{x[i]:.1}\")\n",
    "# this will avoid the length cell especially in github notebook renderer and nbv viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5e259-3072-4b44-8ded-54c21d667f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633c074-4023-49ac-8448-16d125080610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15a4925b-c59b-4e40-ba81-9bc23e50ab6e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfae5fb-c982-406a-ac3f-930c8de07448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in s (str) - checks is 1st character #? \n",
    "#if yes then stores in portfolio a\n",
    "# otherwise it stores an empty string\n",
    "def points_to_array(s):\n",
    "    portfolio = ''\n",
    "    if s[0] == '#':\n",
    "        portfolio = '#'\n",
    "        random = ''\n",
    "        #checks the last character  if its an asterisk then it stores \n",
    "        if s[-1] == '*':\n",
    "            random = '*'\n",
    "            # loops through each characters in string for i in s\n",
    "            # + is string concatenation \n",
    "            # + is not addition\n",
    "        points = ''\n",
    "        for i in s:\n",
    "            if i.isdigit():\n",
    "                points = points + 1\n",
    "                return [points, portfolio, random]\n",
    "            \n",
    "# 'would recommend changing course _points[0], course_points[1]] into arrays with three things in them\n",
    "#hash character , empty string, points ,random has- maybe don't need if read in pandas'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01087dbc-03d7-45e0-881c-fd46073c97e9",
   "metadata": {},
   "source": [
    "#### Extra lines in html- how to reconcile the # lines of html vs the csv\n",
    "- i.e. total number of lines output in jupyter code\n",
    "- open VSC\n",
    "- delete all the lines that don't want\n",
    "- delete preamble & sections within colleges\n",
    "\n",
    "####  find \\n\\n and replace with \\n\n",
    "in RE turned on : ^ looks for start of line $ looks for end of line <br>\n",
    "cant find and replace with these but can find S&F of lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a125451-d860-4b31-b7fb-a96b41212252",
   "metadata": {},
   "source": [
    "#### alternate way to sort\n",
    "- different to RE but similar result\n",
    "- more manual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d5f37-c917-4d26-866e-5f6cca161c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the filepath for the alternate csv file- which is the output of the below script that uses a more 1st principles approach\n",
    "path2021csv2 = 'data/cao2021_csv(2)' + now.strftime('%Y%m%d_%H%M%S')  + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475fa96-f538-4041-b686-a0f64abffc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# older version of code\n",
    "\n",
    "no_lines = 0\n",
    "#open the csv file for writing\n",
    "with open(path2021csv2, 'w') as f:\n",
    "    # write a header row\n",
    "    f.write(','.join(['code', 'title', 'pointsR1', 'pointsR2']) + '\\n')\n",
    "    #debug:\n",
    "            ##print(len(linesplit), linesplit ,dline)\n",
    "            #this will show you how the RE is splitting \n",
    "            #i.e. expect '4' for len(length) of linesplit, then in square brackets how it splits 'xxx', then outside square brackets the string- 'dline'\n",
    "            \n",
    "            #print out just the course code # :5b means simply print out the characters up to position 5 (0-4 in python)\n",
    "            #course_code = dline[:5]\n",
    "            #print (course_code)\n",
    "            \n",
    "            #print out just the course title- starts at 7n in..trial and error re run until get longest course title\n",
    "            #course_title = dline[7:57]\n",
    "            #print (course_title)     \n",
    "            \n",
    "            #round one points - prints out both round 1 and round 2  Note: can't separate 'round' and '1'\n",
    "            #course_round1 = dline[60:]\n",
    "            #print (course_round1)\n",
    "            \n",
    "            #can edit the RE and re-run these to debug further\n",
    "            \n",
    "            #further debugging\n",
    "            #split on the space. Has a look for one ore more space and splits it\n",
    "            #course_points = re.split('  +' , dline[60:])\n",
    "            #print(f\"'{course_code} {course_points}'\")\n",
    "            \n",
    "            #last line is returning anything but two substrings back- create an exception\n",
    "           # if len(course_points) != 2:\n",
    "                #course_points = course_points[:2]\n",
    "               # join the fields usign a comma\n",
    "               # linesplit = [course_code,course_title, course _points[0], course_points[1]]\n",
    "                \n",
    "            #print(','.join(linesplit))\n",
    "            #f.write(csv_version + '\\n') - saving of old RE way\n",
    "            #rejoin the substrings with commas in-between\n",
    "            #f.write(','.join(linesplit) + '\\n')\n",
    "            \n",
    "            #result - output is a csv file!\n",
    "    for line in resp.iter_lines():\n",
    "        dline = line.decode('cp1252')\n",
    "        if re_course.fullmatch(dline):\n",
    "            no_lines = no_lines + 1\n",
    "            course_code = dline[:5]\n",
    "            course_title = dline[7:57].strip()\n",
    "            course_points = re.split('  +' , dline[60:])\n",
    "            if len(course_points) != 2:\n",
    "                course_points = course_points[:2]\n",
    "            linesplit = [course_code,course_title, course_points[0], course_points[1]]\n",
    "            f.write(','.join(linesplit) + '\\n') \n",
    "            print(line) # to check the output- can be commented out as required\n",
    "print(f\"total number of lines is {no_lines}.\")\n",
    "\n",
    "# output path2021 is a csv file\n",
    "#note pandas coud convert html to csv but better to use own code and save as csv- use pandas thereafter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2709c6-c422-4ce0-bd41-9649cf1cd642",
   "metadata": {},
   "source": [
    "stripstrings = ' abc     ' <br>\n",
    "**s.strip()** strips the white space** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ced06-ee21-4420-b152-6ad3ca0e8b2e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**NB** it was verfied as pof  xx yy zz that there were  949 courses exactly in the CAO 2021 points list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d03af-4353-48c3-bfd3-c5606119c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code\n",
    "#how to loop throught the linesv in request. iterate through the lines in request using a regular expression\n",
    "#for line in resp.iter_lines():\n",
    "   # if re.match('[A-Z]{2}[0-9]{3}  .* *(0-9){3} *', line.decode('utf-8') ):\n",
    "               # print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d2efc-4b5c-484e-a1bb-fcc72255dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021 = pd.read_csv(path2021, encoding='cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14377b3-09e6-4865-a270-03fcda1ed403",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 2020 points\n",
    "\n",
    "http://www.cao.ie/index.php?page=points&p=2020\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3547d5f-c92c-4c18-adb5-ae88829f4c62",
   "metadata": {},
   "source": [
    "### download and parse the excel spreadsheet using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b349e84-e5e9-48bf-be11-6cafa08f7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a variable for the url to keep it neat\n",
    "url2020 = 'http://www2.cao.ie/points/CAOPointsCharts2020.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4594b3e-1b1a-410a-9214-a632a295dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and parse the excel spreadsheet\n",
    "#skip the 1st 10 preamble rows\n",
    "df2020 = pd.read_excel (url2020, skiprows = 10)\n",
    "# however it reads the 1st 10 preamble headings \n",
    "# could save file and manually delete 1st 10 rows but better to use pandas functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4815874-5719-466a-a538-417a3c467618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a88a8-32cc-450e-9589-74a27909e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spot check of data\n",
    "# use loc or iloc functionality to check data\n",
    "df2020.iloc[12]\n",
    "#check the final line in the spreadsheet\n",
    "# reminder 1st 11 rows are heading #excel identifies 1st row as zero\n",
    "df2020.iloc[753]\n",
    "# can also count backwards to last row\n",
    "df2020.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd208447-3c48-4ab9-b923-ec2c9f2c4afa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### save original file \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa405efd-b47a-4d9d-a4d1-eb3195de7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathxlsx = 'data/cao2020_' + now.strftime('%Y%m%d_%H%M%S')  + '.xlsx'\n",
    "now.strftime('%Y%m%d_%H%M%S')\n",
    "#save the original html file\n",
    "with open(pathxlsx, 'w') as f:\n",
    "    f.write(resp.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738435a1-1d28-47ce-924b-60ac519041b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib save the original file to disk\n",
    "\n",
    "urlrq.urlretrieve (url2020, pathxlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94a208-ad1b-48bc-ae6f-b28a2029b8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24badb73-d367-4784-9d81-a096d81d6743",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### create a filepath for pandas data\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f7367-e39d-47fb-a44f-67822ae7d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the output to a csv file\n",
    "path2020 = 'data/cao2020_' + now.strftime('%Y%m%d_%H%M%S')  + '.csv'\n",
    "df2020.to_csv(path2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88608396-a2cc-4ce5-b11f-a5eb7f7a23e0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_excel.htmlpandas.read_excel <br> function signature in pandas excel webpage: (io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skipfooter=0, convert_float=None, mangle_dupe_cols=True, storage_options=None)Â¶\n",
    "skiprows is what we need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21013d1-0794-4779-97d8-ef5fed6aab59",
   "metadata": {},
   "source": [
    "## fetch earlier year points data and save in data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241ccb2-a3bf-4ded-b45a-be29d2db2581",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2019 points\n",
    "-as pdf option here is to read do it manually before getting pandas to read it as a csv\n",
    "\n",
    "http://www.cao.ie/index.php?page=points&p=2019\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebe4cb-0553-4268-af07-bcab507a9990",
   "metadata": {},
   "source": [
    "-Note the 2019 and earlier points are in pdf format<br>\n",
    "Main points inndex url: <br>\n",
    "https://www.cao.ie/index.php?page=points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117640c-f8a2-489a-a8c6-7e1535f46995",
   "metadata": {},
   "source": [
    "<br>\n",
    "### steps to reproduce the 2019 editable:\n",
    "****\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50a66103-ea8c-47d7-afc9-5ee02a57a103",
   "metadata": {},
   "source": [
    "Python libraries to check out to 'scrape pdf's':\n",
    "\n",
    "Tabula,Camelot,Excalibur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c907b3-429f-43e4-987c-8064b60caa86",
   "metadata": {},
   "source": [
    "Manual way of extracting:\n",
    "1. save pdf in repository\n",
    "2. open original with MS Word (may need to 'choose other app to open' in dropdown\n",
    "3. MS Word converts pdf to Word\n",
    "4. Save file as xxxxx.docx format\n",
    "5. Resave a copy to edit in repo as xxxxx_edited.docx\n",
    "6  Delete headers and footers\n",
    "7. delete preamble on page 1\n",
    "8. Ctrl 'A', Ctrl 'C' to copy all data in the 21 separate tables\n",
    "9. Open notepad++ and paste 'Ctrl V'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b839e7-1407-40c7-ad09-2ad26172639e",
   "metadata": {},
   "source": [
    "### manual editing in notepad ++\n",
    "1. Add HEI to header\n",
    "2.Select the 'College/Institute' i.e. 'Athlone Institute of Technology'\n",
    "3. Ctrl X to cut\n",
    "4. Move cursor to in front of AIT 1st course line\n",
    "5. Hold down ALT key and drag cursor down to all AIT courses\n",
    "6. Ctrl V to paste - click 'tab' key to create tabs\n",
    "7. Delete blank lines\n",
    "8. Put double quotes around college names as they have commas [select start of string with cursor-alt-type \"]\n",
    "9. Change backticks to apostrophes\n",
    "10. optional : \\t  in extended file 'replace all' with comma: replaces all the tabs with commas <br> however not recommended here as commas elsewhere will confuse. <br> best to leave tabs as delimiters  e.g. in effect its as 'tsv' tab serapated file but can save as csv\n",
    "11. find \\\\t replace with \\t finds the double tabs and removes them\n",
    "11. save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddad8d-61f0-46a3-9d21-195fac01a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019 = pd.read_csv('data/cao2019_20211102_191031_edited.csv', sep ='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32471d98-9b9e-4a95-bb1f-8ad32a2e9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24f14d-8f57-481e-a4a5-e81a7aebfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the CAO points URL.  The url for earlier years takes you to a pdf version\n",
    "# However the python code to fetch appears to work\n",
    "resp = rq.get ('http://www2.cao.ie/points/lvl8_19.pdf')\n",
    "#have a quick peek\n",
    "resp\n",
    "# resp [200] means html response is in order.  [404] if returns means it is not found .  These are http codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b3fe6-10f3-4934-b67e-2caf6782d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2019 = 'data/cao2019_' + now.strftime('%Y%m%d_%H%M%S')  + '.html'\n",
    "now.strftime('%Y%m%d_%H%M%S')\n",
    "#save the original html file\n",
    "with open(path2019, 'w') as f:\n",
    "    f.write(resp.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa55fa4-88bd-489b-aa7e-c2a0acc13779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e42a0-53a5-44c0-a427-9f60ce3ef71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9a2f5-b95c-45ee-9349-df53e9e2d7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a832b31a-cc88-48c5-a8d9-634307c2772c",
   "metadata": {},
   "source": [
    "#### fetch 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2910fba-8bad-4609-b2c6-2baa4bdfddd0",
   "metadata": {},
   "source": [
    "**propose to go through the same process as 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e3d55-b7f0-4695-8aa0-627f78676a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = rq.get ('http://www2.cao.ie/points/lvl8_18.pdf')\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb094ba2-7fcf-4466-aea7-5425a15978dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2018 = 'data/cao2018_' + now.strftime('%Y%m%d_%H%M%S')  + '.html'\n",
    "now.strftime('%Y%m%d_%H%M%S')\n",
    "#save the original html file\n",
    "with open(path2018, 'w') as f:\n",
    "    f.write(resp.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f972d-0be4-4880-a528-f448d70e46b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422e3ef6-77e9-4a89-a83b-2c5b63c5da6a",
   "metadata": {},
   "source": [
    "###How to convert pdf to csv in python- further reading: <br>\n",
    "-https://stackoverflow.com/questions/49560486/how-to-convert-pdf-to-csv-with-tabula-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cc42b-990f-4cdc-addc-85833ae5492e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Concatenate and Merge dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656ab20-5b2a-4e9a-b1fa-991912d62fa3",
   "metadata": {},
   "source": [
    "how to concatenate with pandas <br>\n",
    "note 'ignore_index'= True <br>\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html <br>\n",
    "how to manage duplicates in a dataframe <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html <br>\n",
    "how to return uniques in dastaframe columns <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html <br>\n",
    "how to drop duplicates in dataframe <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565db36-0205-4f6e-b0bf-71556741eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the required columns (course and points) from the dataframe\n",
    "courses2021= df2021[['code' , 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9f6935-c8e7-4891-9c7a-85eb259c37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a860a122-bdda-4daa-895a-05579119118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2020= df2020[['COURSE CODE2' , 'COURSE TITLE']]\n",
    "# change the title of the columns to match 2021\n",
    "courses2020.columns = ['code' ,'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c9727-cb63-462f-8171-adcfd3cd46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4df0d-1c75-4a81-92e1-5e3c98ff0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge or concatenate the two datasets into one dataframe\n",
    "#set ignore_index = True (default is False)\n",
    "allcourses = pd.concat([courses2021, courses2020], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a0db6-5ab5-435e-99e3-9812328c9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50691516-f667-454d-a640-e9fe24e9fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a false for every row that are not duplicated\n",
    "allcourses.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332245b-d34a-4401-9ba0-21531e93a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds all extra copies of duplicated rows\n",
    "#duplicated by default doesnt set the 1st iteration of the matching rows as true (returns false)\n",
    "allcourses[allcourses.duplicated()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e8820-4037-48f6-b56b-5c4fcdada3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses[allcourses.duplicated(keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187be41e-223c-4321-89b4-3c0c0cc559eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns back the dataframe with all duplicates dropped\n",
    "allcourses.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b3454-b371-4797-9d7f-4d91f2c527f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just look for duplicates of the code- as the course titles are likely different from year to year\n",
    "allcourses[allcourses.duplicated(subset =['code'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d0783-efba-4248-b00f-8ed3db6bd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates based on the same code\n",
    "allcourses.drop_duplicates(subset=['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb222b-67c4-4b74-9e09-bc339d570649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates based on the same code\n",
    "#creates a new dataframe as by default-this is identified by 'inplace=False'\n",
    "#ignore_index cleans up the duplicates in the index i.e. counts just one of duplicates indexes\n",
    "allcourses.drop_duplicates(subset=['code'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ccfe3-7dda-4085-9d44-3a053c32b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we used inplace=True then we have permanentlty unduplicated the dataframe for codes\n",
    "#when run allcourses this time the default dtaframe has no course code duplicates\n",
    "allcourses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6288b68-dc70-4bc3-b4a0-83928c4405cb",
   "metadata": {},
   "source": [
    "reset index in pandas dataframe<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da5dad-4ad7-469e-9300-ac0d7c9f032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by courses\n",
    "allcourses.sort_values ('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69236410-8c47-4967-8bbc-25a03be1eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f6903-c6eb-4844-9fee-f950149b3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcourses.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2465c-b5f5-4bea-a084-d34889652e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e0bfe6-7463-4099-af63-c98f74efa1e9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Join to the Points \n",
    "***\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609154e-7c26-4a39-8700-1a391eb25616",
   "metadata": {},
   "source": [
    "worth knowing: pandas dataframe.join\n",
    "how:\n",
    "**main event is left**\n",
    "- left join: - whatever df is on the left (join call) the other is on the right . keeps everything from the left\n",
    "- only join: keeps values in BOTH dataframes\n",
    "- right join: keeps everything in the right dataframe\n",
    "- full-outer join merges everything- (have a lot of NaN's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5bd6c-0f24-4b6e-95cb-2374c0f56ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988227d-1bc2-456b-bd98-98d35816f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the index to the code column\n",
    "df2021.set_index ('code', inplace=True)\n",
    "df2021.columns = ['title' , 'points_r1_2021', 'points_r2_2021']\n",
    "df2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b6297-281e-4d46-a116-7bb2006b3076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464057a-1b63-4d82-92ae-340c8ad01da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the points from 2021 and 2020\n",
    "#see pandas concatenate reference above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d798c-fdc5-4d45-a297-0f216df1b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the column as the index\n",
    "allcourses.set_index('code', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9957a-978d-468f-be73-9de6856e941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just merge what you need from the 2021 dataframe i.e. code and points\n",
    "#where NaN it defines as code that was not run in 2021\n",
    "allcourses = allcourses.join(df2021[['points_r1_2021']])\n",
    "allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e5fef-6de0-4d88-8842-2e757850be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just need to join the pointd from 2020\n",
    "df2020_r1= df2020 [['COURSE CODE2', 'R1 POINTS']]\n",
    "df2020_r1.columns = ['code', 'points_R1_2020']\n",
    "df2020_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f381eb-36aa-431b-9c31-fea06e427628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index to the code column\n",
    "df2020_r1.set_index ('code', inplace=True)\n",
    "df2020_r1                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1cfd4-d762-483c-b1b2-f49b06ba23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just merge what you need from the 2021 dataframe i.e. code and points\n",
    "#where NaN it defines as code that was not run in 2021\n",
    "#join2020 points to all courses\n",
    "#allcourses = allcourses.join(df2021[['pointsR1']])\n",
    "#allcourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2efc9-ea63-433d-8e28-57ae75bf58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 2020 points to all courses\n",
    "allcourses = allcourses.join(df2020_r1)\n",
    "allcourses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5b09b-171c-421b-896f-2e02660618bb",
   "metadata": {},
   "source": [
    "https://www.prepressure.com/library/technology/ascii-binary-hex\n",
    "\n",
    "http://www.i18nqa.com/debug/table-iso8859-1-vs-windows-1252.html\n",
    "\n",
    "https://docs.python.org/3/library/datetime.html\n",
    "\n",
    "https://www.ibm.com/ie-en/products/spss-statistics-gradpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0907a72-bf96-4e2d-a5d1-988f0bcd35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strftime turns datetime to strings\n",
    "#strptime turns strings into datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306abfc-99ad-456f-bf1b-71f94a7e4f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6967d-af3c-4533-a98a-a08c17dd02f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a7bc9-9f46-4f7b-963f-a9fb7091d0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13a2ea82-860d-4447-b01c-736e700c6223",
   "metadata": {},
   "source": [
    "#### SPSS\n",
    "SPSS currently owned by IBM <br> \n",
    "All click and point <br>\n",
    "Not as powerful as Python <br>\n",
    "'Level of Measurement'<br>\n",
    "Typically dealing with one table of data <br>\n",
    "Similar functionality but less friendly than Excel <br>\n",
    "clone function (open source) called PSPP <br>\n",
    "Laerd: Really high quality stastistical explanations <br>\n",
    " to e.g. get a good explanation of e..g. One Way Anova type 'Laerd One Way Anova' etc\n",
    "\n",
    "https://www.ibm.com/ie-en/products/spss-statistics-gradpack <br>\n",
    "https://www.gnu.org/software/pspp/ (PSPP) <br>\n",
    "https://statistics.laerd.com/ (Laerd) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42812f-025e-4474-b766-14c0be3ed911",
   "metadata": {},
   "source": [
    "### Categorical (Variables)\n",
    "- similar to qualitative data\n",
    "- sex\n",
    "- job description\n",
    "- opinion\n",
    "##### Nominal: no inherent order\n",
    "- job category: doctor, accountant\n",
    "##### Ordinal: there is a meaningful order but not a measurable distance between categories\n",
    "-items can be ranked <br>\n",
    "- 1st, 2nd, 3rd<br>\n",
    "- strongle disagree, disagree, neutral, strongly agree<br>\n",
    "- does not allow for relative degree of difference between them\n",
    "### Scale (Variables)\n",
    "typically as INTERVAL or RATIO <br>\n",
    "values can be ordered <br>\n",
    "suggest a distance between values <br>\n",
    "age, salary <br>\n",
    "##### INTERVAL\n",
    "-20C is not twice as hot as 10C<br>\n",
    "##### RATIO\n",
    "-20K is not twice as hot as 10K<br>\n",
    "-true zero point\n",
    "-numercial values can be transfprmed by multiplying each value by a constant\n",
    "\n",
    "\n",
    "##### Further reading\n",
    "1 Stanley Stevens: Invented classifications related to:<br>\n",
    "Level of Measurement <br>\n",
    "Scales of Measurement\n",
    " his original 1946 paper can still be sourced\n",
    "2. Aelph Number\n",
    "3. Cantors Diagonal Argument <br>\n",
    "certain infite sets 0,1,2,3 v 2,4,6,8.. must have same size as can be paired <br>\n",
    " but are actually not the same size\n",
    "4. Ordinal Numbers <br>\n",
    "natural numbers \n",
    "\n",
    "- NOMINAL/ORDINAL/INTERVAL/RATIO <br>\n",
    "\n",
    "-https://symbiosiscollege.edu.in/assets/pdf/e-learning/tyba/Economics/Scales-of-Measurement-6.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6924065-ce76-4242-89f5-4fbbf0bc1b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
